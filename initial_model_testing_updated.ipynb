{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ffab19a8",
      "metadata": {
        "id": "ffab19a8"
      },
      "source": [
        "#### Trying out DensNet121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a78e407d",
      "metadata": {
        "id": "a78e407d"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from torch import optim\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2b5da5c6",
      "metadata": {
        "id": "2b5da5c6"
      },
      "outputs": [],
      "source": [
        "class MyDenseNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.densenet = models.densenet121(pretrained=True)\n",
        "        num_features = self.densenet.classifier.in_features #access the number of input features for last fully connected layer\n",
        "        #replace last fully connected layer with linear layer that matches no of output classes\n",
        "        self.densenet.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Apply Xavier initialization to the linear layer's weights\n",
        "        init.xavier_uniform_(self.densenet.classifier.weight)\n",
        "        if self.densenet.classifier.bias is not None:\n",
        "            init.constant_(self.densenet.classifier.bias, 0)  # Initialize bias if present\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.densenet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d330fdc2",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d330fdc2",
        "outputId": "f564a7e2-2807-4ec5-fbbd-5d0a8b7cbc2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 182MB/s]\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3  # no of classes for classification\n",
        "model = MyDenseNet(num_classes) # initialize our densnet model with the number of classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7567cbb6",
      "metadata": {
        "id": "7567cbb6"
      },
      "source": [
        " As our model still hasn't been trained yet it has not yet learned any patterns from the training data. This code is just to see if the model loading is working with a bunch of images that we have extracted. Here we are making predictions with an untrained model for more of a demonstration of the prediction process itself."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0902b3c6",
      "metadata": {
        "id": "0902b3c6"
      },
      "source": [
        "#### Spliting into Train, Test and Val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c24899c0",
      "metadata": {
        "id": "c24899c0"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import shutil\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7005aaa0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "7005aaa0",
        "outputId": "72aabbc8-f05a-443f-8ddb-c07da9711833"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0321876cd7d3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset'"
          ]
        }
      ],
      "source": [
        "classes = [class_name for class_name in os.listdir('dataset') if os.path.isdir(os.path.join('dataset', class_name))]\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0d044362",
      "metadata": {
        "id": "0d044362"
      },
      "outputs": [],
      "source": [
        "data_folder = 'dataset/C57BL_6J' # this is only for one type, make it dynamic for looping all types of cells\n",
        "train_folder = 'dataset/train_folder'\n",
        "val_folder = 'dataset/val_folder'\n",
        "test_folder = 'dataset/test_folder'\n",
        "\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(val_folder, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e30bf6c5",
      "metadata": {
        "id": "e30bf6c5",
        "outputId": "f04a61a5-450c-4c1a-a398-eb33773382eb"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] The system cannot find the path specified: 'dataset/C57BL_6J'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image_files \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(data_folder)\n\u001b[0;32m      2\u001b[0m random\u001b[39m.\u001b[39mshuffle(image_files)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'dataset/C57BL_6J'"
          ]
        }
      ],
      "source": [
        "image_files = os.listdir(data_folder)\n",
        "random.shuffle(image_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147215df",
      "metadata": {
        "id": "147215df",
        "outputId": "c7ef9ad1-88c6-442b-80ba-f636d8dca24e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'image_files' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m val_ratio \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m\n\u001b[0;32m      3\u001b[0m test_ratio \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m\n\u001b[1;32m----> 5\u001b[0m total_images \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(image_files)\n\u001b[0;32m      6\u001b[0m train_count \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(total_images \u001b[39m*\u001b[39m train_ratio)\n\u001b[0;32m      7\u001b[0m val_count \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(total_images \u001b[39m*\u001b[39m val_ratio)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'image_files' is not defined"
          ]
        }
      ],
      "source": [
        "train_ratio = 0.6\n",
        "val_ratio = 0.2\n",
        "test_ratio = 0.2\n",
        "\n",
        "total_images = len(image_files)\n",
        "train_count = int(total_images * train_ratio)\n",
        "val_count = int(total_images * val_ratio)\n",
        "\n",
        "train_files = image_files[:train_count]\n",
        "val_files = image_files[train_count:train_count + val_count]\n",
        "test_files = image_files[train_count + val_count:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5b85fa2",
      "metadata": {
        "id": "d5b85fa2"
      },
      "outputs": [],
      "source": [
        "for filename in train_files:\n",
        "    shutil.move(os.path.join(data_folder, filename), os.path.join(train_folder, filename))\n",
        "\n",
        "for filename in val_files:\n",
        "    shutil.move(os.path.join(data_folder, filename), os.path.join(val_folder, filename))\n",
        "\n",
        "for filename in test_files:\n",
        "    shutil.move(os.path.join(data_folder, filename), os.path.join(test_folder, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55dae112",
      "metadata": {
        "id": "55dae112"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = ImageFolder('dataset/train_folder', transform=transform)\n",
        "val_dataset = ImageFolder('dataset/test_folder', transform=transform)\n",
        "test_dataset = ImageFolder('dataset/val_folder', transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb6c8b40",
      "metadata": {
        "id": "cb6c8b40"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52d4c4c",
      "metadata": {
        "id": "a52d4c4c"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss() # We use Cross Entropy Loss, as this is a classification task\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001) # If in doubt, we use Adam as our optimiser\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001) # If in doubt, we use Adam as our optimiser\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "milestones = [10, 18, 24]  # List of epochs where the learning rate will be decreased\n",
        "gamma = 0.1  # Factor by which the learning rate will be decreased\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=gamma)  # Adjust step_size according to your preference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac64df78",
      "metadata": {
        "id": "ac64df78"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, loss_fn, optimizer, device):\n",
        "    model.train() # puts the model in training mode\n",
        "    running_loss = 0\n",
        "    with tqdm(total=len(train_loader)) as pbar:\n",
        "        for i, data in enumerate(train_loader, 0): # loops through training data\n",
        "            inputs, labels = data # separate inputs and labels (outputs)\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # puts the data on the GPU\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            optimizer.zero_grad() # clear the gradients in model parameters\n",
        "            outputs = model(inputs) # forward pass and get predictions\n",
        "            loss = loss_fn(outputs, labels) # calculate loss\n",
        "            loss.backward() # calculates gradient w.r.t to loss for all parameters in model that have requires_grad=True\n",
        "            optimizer.step() # iterate over all parameters in the model with requires_grad=True and update their weights.\n",
        "\n",
        "            running_loss += loss.item() # sum total loss in current epoch for print later\n",
        "\n",
        "            pbar.update(1) #increment our progress bar\n",
        "\n",
        "    return running_loss/len(train_loader) # returns the total training loss for the epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee332b2",
      "metadata": {
        "id": "2ee332b2"
      },
      "outputs": [],
      "source": [
        "# Function for the validation pass\n",
        "\n",
        "def validation(model, val_loader, loss_fn, device):\n",
        "    model.eval() # puts the model in validation mode\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad(): # save memory by not saving gradients which we don't need\n",
        "        with tqdm(total=len(val_loader)) as pbar:\n",
        "            for images, labels in iter(val_loader):\n",
        "                images, labels = images.to(device), labels.to(device) # put the data on the GPU\n",
        "                outputs = model(images) # passes image to the model, and gets a ouput which is the class probability prediction\n",
        "\n",
        "                val_loss = loss_fn(outputs, labels) # calculates val_loss from model predictions and true labels\n",
        "                running_loss += val_loss.item()\n",
        "                _, predicted = torch.max(outputs, 1) # turns class probability predictions to class labels\n",
        "                total += labels.size(0) # sums the number of predictions\n",
        "                correct += (predicted == labels).sum().item() # sums the number of correct predictions\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "        return running_loss/len(val_loader), correct/total # return loss value, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "004f7524",
      "metadata": {
        "id": "004f7524",
        "outputId": "796c4cf7-e56e-40be-a40c-c887b59fa39d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MyDenseNet(\n",
              "  (densenet): DenseNet(\n",
              "    (features): Sequential(\n",
              "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu0): ReLU(inplace=True)\n",
              "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (denseblock1): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (transition1): _Transition(\n",
              "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "      (denseblock2): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer7): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer8): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer9): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer10): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer11): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer12): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (transition2): _Transition(\n",
              "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "      (denseblock3): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer7): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer8): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer9): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer10): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer11): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer12): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer13): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer14): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer15): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer16): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer17): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer18): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer19): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer20): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer21): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer22): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer23): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer24): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (transition3): _Transition(\n",
              "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "      (denseblock4): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer7): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer8): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer9): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer10): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer11): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer12): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer13): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer14): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer15): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer16): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Determine whether a GPU is available\n",
        "model.to(device) # send model to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "675be5f2",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "afe60d038c064b469ca12fdfb198e1ba",
            "a0252a3561614a469dc7580dd3f88140",
            "be32b5c77fde456dbe10c4e68bd756d5",
            "aecf16a8ac2f4b4389bbba2485262ce1",
            "9c69f3e534a04404839b8a73b1dc2d3b"
          ]
        },
        "id": "675be5f2",
        "outputId": "3ef28cf2-8585-4021-a7d7-fca503e6b3b6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afe60d038c064b469ca12fdfb198e1ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0252a3561614a469dc7580dd3f88140",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/30, Training Loss: 0.3377733826637268, Val Loss: 1.091655969619751, Val Accuracy: 0.4444444444444444\n",
            "--------------------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be32b5c77fde456dbe10c4e68bd756d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aecf16a8ac2f4b4389bbba2485262ce1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2/30, Training Loss: 0.13250131905078888, Val Loss: 1.2508097887039185, Val Accuracy: 0.4444444444444444\n",
            "--------------------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c69f3e534a04404839b8a73b1dc2d3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m accuracies \u001b[39m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(total_epoch): \u001b[39m# loops through number of epochs\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_loader, loss_fn, optimizer, device)  \u001b[39m# train the model for one epoch\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     val_loss, accuracy \u001b[39m=\u001b[39m validation(model, val_loader, loss_fn, device) \u001b[39m# after training for one epoch, run the validation() function to see how the model is doing on the validation dataset\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[39m# keep track of interesting stuff\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[11], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs) \u001b[39m# forward pass and get predictions\u001b[39;00m\n\u001b[0;32m     12\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, labels) \u001b[39m# calculate loss\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m loss\u001b[39m.\u001b[39;49mbackward() \u001b[39m# calculates gradient w.r.t to loss for all parameters in model that have requires_grad=True\u001b[39;00m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[39m.\u001b[39mstep() \u001b[39m# iterate over all parameters in the model with requires_grad=True and update their weights.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m# sum total loss in current epoch for print later\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "total_epoch = 30 # Define how many epochs of training we want\n",
        "\n",
        "# keep track of things we'd like to plot later\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "accuracies = []\n",
        "\n",
        "for epoch in range(total_epoch): # loops through number of epochs\n",
        "    train_loss = train(model, train_loader, loss_fn, optimizer, device)  # train the model for one epoch\n",
        "    # Update the learning rate scheduler\n",
        "    scheduler.step()\n",
        "    val_loss, accuracy = validation(model, val_loader, loss_fn, device) # after training for one epoch, run the validation() function to see how the model is doing on the validation dataset\n",
        "\n",
        "    # keep track of interesting stuff\n",
        "    training_losses.append(train_loss)\n",
        "    validation_losses.append(val_loss)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    print(\"Epoch: {}/{}, Training Loss: {}, Val Loss: {}, Val Accuracy: {}\".format(epoch+1, total_epoch, train_loss, val_loss, accuracy))\n",
        "    print('-' * 20)\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# Save the queen\n",
        "torch.save(model.state_dict(), 'finished')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c154cc5",
      "metadata": {
        "id": "2c154cc5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}